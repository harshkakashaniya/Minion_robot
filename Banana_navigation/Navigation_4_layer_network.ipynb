{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the first project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893).\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Banana.app\"`\n",
    "- **Windows** (x86): `\"path/to/Banana_Windows_x86/Banana.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Banana_Windows_x86_64/Banana.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Banana_Linux/Banana.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Banana_Linux/Banana.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Banana.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Banana.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "handle is closed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-64e43fe24254>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnityEnvironment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/home/hbk_il/deep-reinforcement-learning/Banana_Linux/Banana.x86\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_name, worker_id, base_port, curriculum, seed, docker_training, no_graphics)\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0maca_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_academy_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrl_init_parameters_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnityTimeOutException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36msend_academy_parameters\u001b[0;34m(self, init_parameters)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnityInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrl_initialization_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrl_initialization_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrap_unity_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrl_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnityRLInput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnityOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/rpc_communicator.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0;34m\"You may need to manually close a previously opened environment \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \"or use a different worker number.\".format(str(self.worker_id)))\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             raise UnityTimeOutException(\n\u001b[1;32m     60\u001b[0m                 \u001b[0;34m\"The Unity environment took too long to respond. Make sure that :\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;34m\"\"\"Whether there is any input available to be read\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_check_closed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"handle is closed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: handle is closed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception calling application: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hbk_il/anaconda3/envs/drlnd/lib/python3.6/site-packages/grpc/_server.py\", line 385, in _call_behavior\n",
      "    return behavior(argument, context), True\n",
      "  File \"/home/hbk_il/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/rpc_communicator.py\", line 25, in Exchange\n",
      "    self.child_conn.send(request)\n",
      "  File \"/home/hbk_il/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/home/hbk_il/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/hbk_il/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"/home/<user-name>/deep-reinforcement-learning/Banana_Linux/Banana.x86\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States look like: [1.         0.         0.         0.         0.84408134 0.\n",
      " 0.         1.         0.         0.0748472  0.         1.\n",
      " 0.         0.         0.25755    1.         0.         0.\n",
      " 0.         0.74177343 0.         1.         0.         0.\n",
      " 0.25854847 0.         0.         1.         0.         0.09355672\n",
      " 0.         1.         0.         0.         0.31969345 0.\n",
      " 0.        ]\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action (uniformly) at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network with 3 Hidden layers.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=64, fc2_units=64):\n",
    "        \"\"\"\n",
    "            Layer 1 :state_size (int): Dimension of each state\n",
    "            Layer 2 : fc1_units (int): Number of nodes in first hidden layer\n",
    "            Layer 3 :fc2_units (int): Number of nodes in second hidden layer\n",
    "            Layer 4 :action_size (int): Dimension of each action\n",
    "        \"\"\"\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc4 = nn.Linear(fc2_units, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        \n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. DQN agent!\n",
    "\n",
    "\"\"\"Used to update the neural network.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 64         # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR = 5e-4               # learning rate \n",
    "UPDATE_EVERY = 4        # how often to update the network\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Agent():\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed):\n",
    "        \n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(seed)\n",
    "\n",
    "        # Q-Network\n",
    "        self.qnetwork_local = QNetwork(state_size, action_size, seed).to(device)\n",
    "        self.qnetwork_target = QNetwork(state_size, action_size, seed).to(device)\n",
    "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=LR)\n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, seed)\n",
    "        # Initialize time step (for updating every UPDATE_EVERY steps)\n",
    "        self.t_step = 0\n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        # Save experience in replay memory\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "        \n",
    "        # Learn every UPDATE_EVERY time steps.\n",
    "        self.t_step = (self.t_step + 1) % UPDATE_EVERY\n",
    "        if self.t_step == 0:\n",
    "            # If enough samples are available in memory, get random subset and learn\n",
    "            if len(self.memory) > BATCH_SIZE:\n",
    "                experiences = self.memory.sample()\n",
    "                self.learn(experiences, GAMMA)\n",
    "\n",
    "    def act(self, state, eps=0):\n",
    "        \n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        self.qnetwork_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.qnetwork_local(state)\n",
    "        self.qnetwork_local.train()\n",
    "\n",
    "        # Epsilon-greedy action selection\n",
    "        if random.random() > eps:\n",
    "            return np.argmax(action_values.cpu().data.numpy())\n",
    "        else:\n",
    "            return random.choice(np.arange(self.action_size))\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        \n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        # Get max predicted Q values (for next states) from target model\n",
    "        Q_targets_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        # Compute Q targets for current states \n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "\n",
    "        # Get expected Q values from local model\n",
    "        Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        # Minimize the loss\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # ------------------- update target network ------------------- #\n",
    "        self.soft_update(self.qnetwork_local, self.qnetwork_target, TAU)                     \n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            local_model (PyTorch model): weights will be copied from\n",
    "            target_model (PyTorch model): weights will be copied to\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)  \n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "  \n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size=37, action_size=4, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 0.85\tAverage Score: 0.854\n",
      "Episode 200\tAverage Score: 3.49\tAverage Score: 3.498\n",
      "Episode 300\tAverage Score: 7.760\tAverage Score: 7.76\n",
      "Episode 400\tAverage Score: 11.34\tAverage Score: 11.34\n",
      "Episode 488\tEpisode Score: 17.00\tAverage Score: 13.00\n",
      "Environment solved in 388 episodes!\tAverage Score: 13.00\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def dqn(n_episodes=2000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        score = 0\n",
    "        state = env_info.vector_observations[0]\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, eps)\n",
    "            env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "            next_state = env_info.vector_observations[0]   # get the next state\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            done = env_info.local_done[0]\n",
    "#             if i_episode>500 and i_episode%10==0:\n",
    "#                 time.sleep(0.05)\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tEpisode Score: {:.2f}\\tAverage Score: {:.2f}'.format(i_episode, score , np.mean(scores_window)), end=\"\")\n",
    "#         print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=13.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            break\n",
    "    torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "    env.close()\n",
    "    return scores\n",
    "\n",
    "scores = dqn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plots for episode vs rewards\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnityEnvironmentException",
     "evalue": "No Unity environment is loaded.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnityEnvironmentException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9dbc617f3cd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msum_reward\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0menv_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_observations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mctr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, train_mode, config, lesson)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mUnityEnvironmentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No Unity environment is loaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mvector_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAllBrainInfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnityEnvironmentException\u001b[0m: No Unity environment is loaded."
     ]
    }
   ],
   "source": [
    "# Test agent for visualization\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# agent_test.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\n",
    "import time\n",
    "reward_total=0\n",
    "for j in range(4):\n",
    "    sum_reward=0\n",
    "    env_info = env.reset(train_mode=False)[brain_name]\n",
    "    state = env_info.vector_observations[0]\n",
    "    ctr=0\n",
    "    while True :\n",
    "        action = agent_test.act(state)\n",
    "        env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "        next_state = env_info.vector_observations[0]   # get the next state\n",
    "        reward = env_info.rewards[0]                   # get the reward\n",
    "        time.sleep(0.05)\n",
    "#         if reward!=0:\n",
    "#             print(reward,ctr)\n",
    "        sum_reward +=reward\n",
    "        done = env_info.local_done[0]                  # see if episode has finished\n",
    "        state = next_state\n",
    "        if done:\n",
    "            break \n",
    "    reward_total +=sum_reward\n",
    "    print(reward_total,j)\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}